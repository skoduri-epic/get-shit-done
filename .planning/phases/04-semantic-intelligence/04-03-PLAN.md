---
phase: 04-semantic-intelligence
plan: 03
type: execute
wave: 2
depends_on: [04-01]
files_modified:
  - commands/gsd/analyze-codebase.md
  - package.json
autonomous: true

must_haves:
  truths:
    - "Claude creates entity files with semantic understanding via /gsd:analyze-codebase"
    - "Entity files include purpose, not just syntax"
    - "Batch processing handles 100+ files efficiently"
  artifacts:
    - path: "commands/gsd/analyze-codebase.md"
      provides: "Semantic entity generation instructions for Claude"
      contains: "semantic entities"
    - path: "package.json"
      provides: "Anthropic SDK dependency"
      contains: "@anthropic-ai/sdk"
  key_links:
    - from: "commands/gsd/analyze-codebase.md"
      to: "Task tool"
      via: "Subagent spawning for entity batch processing"
      pattern: "Task.*entity"
---

<objective>
Enhance /gsd:analyze-codebase to create semantic entity files using Claude.

Purpose: Generate entity documentation that captures file PURPOSE (what it does, why it exists), not just syntax (exports/imports). This transforms "2-3 ls commands" of information into genuine semantic understanding.

Output: Updated analyze-codebase.md command with entity generation instructions, @anthropic-ai/sdk dependency (for future direct API use).
</objective>

<execution_context>
@~/.claude/get-shit-done/workflows/execute-plan.md
@~/.claude/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/04-semantic-intelligence/04-RESEARCH.md
@.planning/phases/04-semantic-intelligence/04-01-SUMMARY.md

From research:
- Use @anthropic-ai/sdk for Claude API calls
- claude-sonnet-4-5-20250929 for entity generation (fast, cost-effective)
- Process files in batches to avoid rate limits
- Entity template format already exists

Current analyze-codebase.md:
- Steps 1-8 for bulk codebase scanning
- Creates index.json, conventions.json, summary.md
- Does NOT create entity files

New requirement:
- After indexing, optionally create entity .md files
- Claude (executing the command) reads file content and generates semantic documentation
- No embedded JavaScript in command markdown - Claude IS the executor

Execution model clarification:
- GSD command .md files contain INSTRUCTIONS for Claude to follow
- Claude reads the markdown and executes the instructions using its tools
- Commands cannot contain executable JavaScript - Claude interprets and acts on the instructions
- For batch processing, Claude uses the Task tool to spawn subagents
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add Anthropic SDK dependency</name>
  <files>package.json</files>
  <action>
Add @anthropic-ai/sdk to package.json dependencies:

```json
"dependencies": {
  "sql.js": "^1.12.0",
  "@anthropic-ai/sdk": "^0.52.0"
}
```

Note: Version 0.52.0+ includes Messages API with proper TypeScript support. This dependency enables future direct API integration (e.g., hooks that call Claude API directly). For the /gsd:analyze-codebase command, Claude itself generates the entity content.
  </action>
  <verify>`grep -q "@anthropic-ai/sdk" package.json`</verify>
  <done>@anthropic-ai/sdk added to package.json</done>
</task>

<task type="auto">
  <name>Task 2: Add semantic entity generation to analyze-codebase</name>
  <files>commands/gsd/analyze-codebase.md</files>
  <action>
Update the analyze-codebase.md command to add entity generation after index creation.

1. Update the objective to mention entity generation:
```markdown
<objective>
Scan codebase to populate .planning/intel/ with file index, conventions, and semantic entity documentation.

Works standalone (without /gsd:new-project) for brownfield codebases. Creates:
- index.json for file index
- conventions.json for naming patterns
- summary.md for context injection
- entities/*.md for semantic file documentation (optional)

Output: .planning/intel/index.json, conventions.json, summary.md, entities/*.md
</objective>
```

2. Add Task to allowed-tools (for entity generation via subagent):
```yaml
allowed-tools:
  - Read
  - Bash
  - Glob
  - Write
  - Task
```

3. Add new Step 9 after Step 8 (before completion report). This step provides INSTRUCTIONS for Claude to follow:

```markdown
## Step 9: Generate semantic entities (optional)

After indexing, generate semantic entity files for key codebase files.

### 9a: Select key files for entity generation

From the index, select files for entity generation using these criteria:
- Files with 3+ exports (significant modules)
- Files imported by 5+ other files (dependency hotspots)
- Files in key directories: api/, lib/, utils/, services/, models/
- Limit to 50 files maximum per run (context management)

Skip:
- Test files (*.test.*, *.spec.*)
- Generated files (*.generated.*, *.d.ts)
- Config files (*.config.*)
- Files already with entities in .planning/intel/entities/

### 9b: Create entity directory

```bash
mkdir -p .planning/intel/entities
```

### 9c: Generate entities in batches

For efficient processing, use the Task tool to spawn a subagent for batch entity generation.

**Subagent prompt template:**

```
Generate semantic entity documentation for the following files.

For each file:
1. Read the file content
2. Analyze its purpose, exports, and dependencies
3. Write an entity file to .planning/intel/entities/{slug}.md

Entity template (use EXACTLY this format):

---
path: {file_path}
type: [module|component|util|config|api|hook|service|model]
updated: {today's date YYYY-MM-DD}
status: active
---

# {filename}

## Purpose

[1-3 sentences: What does this file do? Why does it exist? What problem does it solve?]

## Exports

[List each export with signature and brief description]
- `exportName(args): ReturnType` - What it does

## Dependencies

[Internal deps use wiki-links, external use plain text]
- [[slugified-internal-path]] - Why needed
- external-package - Why needed

## Used By

TBD

## Notes

[Optional: patterns, gotchas, or important context]

---

Slug convention: `src/lib/db.ts` -> `src-lib-db` (replace / and . with -, remove extension)

Files to process:
{list of file paths, max 10 per batch}
```

### 9d: Process in batches of 10

For codebases with many key files:
1. Split the selected files into batches of 10
2. Use Task tool for each batch with the prompt template above
3. Wait for each batch to complete before starting the next
4. This prevents context exhaustion and allows progress tracking

### 9e: Verify entity creation

After batch processing:
- Count entities created: `ls .planning/intel/entities/*.md | wc -l`
- Verify they have semantic content (Purpose section, not just syntax)
- The PostToolUse hook will automatically sync new entities to graph.db
```

4. Update Step 10 (renumber from Step 8) to include entity stats:

```markdown
## Step 10: Report completion

Display summary statistics:

```
Codebase Analysis Complete

Files indexed: [N]
Exports found: [N]
Imports found: [N]

Conventions detected:
- Naming: [dominant case] ([percentage]%)
- Directories: [list]
- Patterns: [list]

Entities created: [N] (if entity generation ran)
- Skipped: [N] (already existed or filtered)

Files created:
- .planning/intel/index.json
- .planning/intel/conventions.json
- .planning/intel/summary.md
- .planning/intel/entities/*.md (if entities generated)

Next: Intel hooks will continue incremental learning as you code.
```
```

5. Update success criteria to include entity generation:

```markdown
<success_criteria>
- [ ] .planning/intel/ directory created
- [ ] All JS/TS files scanned (excluding node_modules, dist, build, .git, vendor, coverage)
- [ ] index.json populated with exports and imports for each file
- [ ] conventions.json has detected patterns (naming, directories, suffixes)
- [ ] summary.md is concise (< 500 tokens)
- [ ] entities/*.md created for key files (if Step 9 executed)
- [ ] Entity files have semantic Purpose sections (not just syntax extraction)
- [ ] Statistics reported to user
</success_criteria>
```
  </action>
  <verify>
```bash
# Check command has entity generation step
grep -q "Generate semantic entities" commands/gsd/analyze-codebase.md && echo "PASS: Step 9 exists"

# Check mentions Task tool for batching
grep -q "Task tool" commands/gsd/analyze-codebase.md && echo "PASS: Task batching documented"

# Check entity template is present
grep -q "## Purpose" commands/gsd/analyze-codebase.md && echo "PASS: Entity template included"

# Check batch size documented
grep -q "batches of 10" commands/gsd/analyze-codebase.md && echo "PASS: Batch processing"
```
  </verify>
  <done>analyze-codebase.md includes semantic entity generation via Claude + Task tool batching</done>
</task>

<task type="auto">
  <name>Task 3: Add context section explaining execution model</name>
  <files>commands/gsd/analyze-codebase.md</files>
  <action>
Update the context section to explain how entity generation works.

In the context section, add:

```markdown
**Entity generation:**
Step 9 generates semantic entity files using Claude's understanding of code purpose. Unlike regex-based extraction (exports/imports), this captures WHY code exists.

For large codebases (50+ key files), entity generation uses the Task tool to spawn subagents that process files in batches of 10. This:
- Prevents context exhaustion
- Allows progress tracking
- Enables parallel processing

Entity files are written to `.planning/intel/entities/` and automatically synced to the graph database by the PostToolUse hook.

**When to skip entity generation:**
- Quick index-only scan: Stop after Step 8
- Already have entities: Existing entities won't be overwritten
- Small codebase: May not need formal entities
```

This clarifies:
1. Claude generates entity content (not embedded JavaScript)
2. Task tool handles batching for large codebases
3. Users can skip Step 9 if they just want the index
  </action>
  <verify>
```bash
grep -q "Task tool to spawn subagents" commands/gsd/analyze-codebase.md && echo "PASS: Execution model explained"
```
  </verify>
  <done>Command explains entity generation execution model clearly</done>
</task>

</tasks>

<verification>
After all tasks complete:

1. SDK dependency added:
   ```bash
   grep -q "@anthropic-ai/sdk" package.json && echo "PASS"
   ```

2. Command has entity generation:
   ```bash
   grep -q "Step 9" commands/gsd/analyze-codebase.md && echo "PASS"
   grep -q "semantic entities" commands/gsd/analyze-codebase.md && echo "PASS"
   ```

3. Task tool batching:
   ```bash
   grep -q "Task tool" commands/gsd/analyze-codebase.md && echo "PASS"
   grep -q "batches of 10" commands/gsd/analyze-codebase.md && echo "PASS"
   ```

4. Entity template present:
   ```bash
   grep -q "## Purpose" commands/gsd/analyze-codebase.md && echo "PASS"
   ```

Manual test:
```bash
# Run /gsd:analyze-codebase on a test project
# Verify Steps 1-8 produce index.json, conventions.json, summary.md
# If Step 9 runs, verify .planning/intel/entities/*.md created with semantic content
```
</verification>

<success_criteria>
- [ ] @anthropic-ai/sdk added to package.json
- [ ] Step 9 added for entity generation (instructions for Claude, not embedded JS)
- [ ] Task tool documented for batch processing subagents
- [ ] File selection criteria documented (3+ exports, 5+ dependents, key dirs)
- [ ] 50 file limit per run to manage context
- [ ] Batch processing with batches of 10 via Task tool
- [ ] Entity slug convention documented
- [ ] Execution model explained (Claude generates content, not script execution)
- [ ] Updated success criteria includes entity generation
</success_criteria>

<output>
After completion, create `.planning/phases/04-semantic-intelligence/04-03-SUMMARY.md`
</output>
